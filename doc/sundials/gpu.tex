% ====================================================================
\section{SUNDIALS GPU Programming Model}\label{s:gpu_model}
% ====================================================================

In this section, we introduce the {\sundials} GPU programming model and
highlight {\sundials} GPU features. The model leverages the fact that all of the
{\sundials} packages interact with simulation data either through the shared
vector, matrix, and solver APIs (see \S\ref{s:nvector}, \S\ref{s:sunmatrix},
\S\ref{s:sunlinsol}, and \S\ref{c:sunnonlinsol}) or through user-supplied
callback functions.  Thus, under the model, the overall structure of the user's
calling program, and the way users interact with the {\sundials} packages is
similar to using {\sundials} in CPU-only environments.

Within the {\sundials} GPU programming model, all control logic executes on the
CPU, and all simulation data resides wherever the vector or matrix object
dictates as long as {\sundials} is in control of the program. That is,
{\sundials} will not migrate data (explicitly) from one memory space to another.
Except in the most advanced use cases, it is safe to assume that data is kept
resident in the GPU-device memory space.  The consequence of this is that, when
control is passed from the user's calling program to {\sundials}, simulation
data in vector or matrix objects must be up-to-date in the device memory space.
Similarly, when control is passed from {\sundials} to the user's calling
program, the user should assume that any simulation data in vector and
matrix objects are up-to-date in the device memory space.  To put it succinctly,
\textit{it is the responsibility of the user's calling program to manage data
coherency between the CPU and GPU-device memory spaces} unless unified virtual
memory (UVM), also known as managed memory, is being utilized. Typically, the
GPU-enabled {\sundials} modules provide functions to copy data from the host to
the device and vice-versa as well as support for unmanaged memory or UVM. In
practical terms, the way {\sundials} handles distinct host and device memory
spaces means that \textit{users need to ensure that the user-supplied functions,
e.g. the right-hand side function, only operate on simulation data in the device
memory space} otherwise extra memory transfers will be required and performance
will be poor.  The exception to this rule is if some form of hybrid data
partitioning (achievable with the {\nvecmanyvector} \S\ref{ss:nvec_manyvector})
is utilized.

{\sundials} provides many native shared features and modules that are GPU-enabled.
Currently, these are primarily limited to the NVIDIA CUDA platform
\cite{cuda_site}, although support for more GPU computing platforms such as AMD
ROCm/HIP \cite{rocm_site} and Intel oneAPI \cite{oneAPI_site}, is an area of
active development.  Table \ref{t:gpu_modules} summarizes the shared {\sundials}
modules that are GPU-enabled, what GPU programming environments they support,
and what class of memory they support (unmanaged or UVM).  Users may also
supply their own GPU-enabled \id{N\_Vector}, \id{SUNMatrix}, \id{SUNLinearSolver},
or \id{SUNNonlinearSolver} implementation, and the capabilties will be leveraged
since {\sundials} operates on data through these APIs.

In addition, {\sundials} provides the \id{SUNMemoryHelper} API \S\ref{s:sunmemory}
to support applications which implement their own memory management or memory
pooling.

\begin{table}[htb]
\centering
\caption[List of {\sundials} GPU Enabled Modules.]
{List of {\sundials} GPU Enabled Modules. Note that support for ROCm/HIP
and oneAPI are currently untested, and implicit UVM (i.e. \id{malloc} returning UVM)
is not accounted for.  A The $\dagger$ symbol indicates that the module
inherits support from the {\nvector} module used.}
\label{t:gpu_modules}
\medskip
\begin{tabular}{|r|c|c|c|c|c|} \hline
  Module &
  \begin{sideways} CUDA              \end{sideways} &
  \begin{sideways} ROCm/HIP          \end{sideways} &
  \begin{sideways} oneAPI            \end{sideways} &
  \begin{sideways} Unmanaged memory~ \end{sideways} &
  \begin{sideways} UVM               \end{sideways} \\ \hline\hline
  {\nveccuda}         (\S\ref{ss:nvec_cuda})          & \cm &     &     & \cm & \cm  \\
  {\nvecraja}         (\S\ref{ss:nvec_raja})          & \cm &     &     & \cm & \cm  \\
  {\nvecopenmpdev}    (\S\ref{ss:nvec_openmpdev})     & \cm & \cm & \cm & \cm &      \\
  {\sunmatcusparse}   (\S\ref{ss:sunmat_cusparse})    & \cm &     &     & \cm & \cm  \\
  {\sunlinsolcuspbqr} (\S\ref{ss:sunlinsol_cuspbqr})  & \cm &     &     & \cm & \cm  \\
  {\sunlinsolspgmr}   (\S\ref{ss:sunlinsol_spgmr})    & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  {\sunlinsolspfgmr}  (\S\ref{ss:sunlinsol_spfgmr})   & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  {\sunlinsolsptfqmr} (\S\ref{ss:sunlinsol_sptfqmr})  & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  {\sunlinsolspbcgs}  (\S\ref{ss:sunlinsol_spbcgs})   & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  {\sunlinsolpcg}     (\S\ref{ss:sunlinsol_pcg})      & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  {\sunnonlinsolnewton}      (\S\ref{s:sunnonlinsol_newton})      & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  {\sunnonlinsolfixedpoint}  (\S\ref{s:sunnonlinsol_fixedpoint})  & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$ & $\dagger$  \\
  \hline
\end{tabular}
\end{table}

% ====================================================================
\section{Steps for Using GPU Accelerated SUNDIALS}\label{s:gpu_usage}
% ====================================================================

For any {\sundials} package, the generalized steps a user needs to take
to use GPU accelerated {\sundials} are:
\begin{enumerate}
  \item Utilize a GPU-enabled {\nvector} implementation.  Initial
  data can be loaded on the host, but must be in the device memory
  space prior to handing control to {\sundials}.
  \item Utilize a GPU-enabled {\sunlinsol} linear solver (if necessary).
  \item Utilize a GPU-enabled {\sunmatrix} implementation (if using a
  matrix-based linear solver).
  \item Utilize a GPU-enabled {\sunnonlinsol} nonlinear solver (if necessary).
  \item Write user-supplied functions so that they use data only in the
  device memory space (again, unless an atypical data partitioning is used).
  A few examples of these functions are the right-hand side evaluation
  function, the Jacobian evalution function, or the preconditioner evaulation
  function.  In the context of CUDA and the right-hand side function, one way a
  user might ensure data is accessed on the device is, for example, calling a
  CUDA kernel, which does all of the computation, from a CPU function which simply
  extracts the underlying device data array from the {\nvector} object that is
  passed from {\sundials} to the user-supplied function.
\end{enumerate}
Users should refer to Table \ref{t:gpu_modules} for a list of GPU-enabled
native {\sundials} modules.